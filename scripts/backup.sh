#!/bin/bash

# Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ñ‹Ñ… ÐºÐ¾Ð¿Ð¸Ð¹ AI Chat Bot
# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ: ./scripts/backup.sh [type]

set -e

# Ð¦Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}"
    exit 1
}

# ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
BACKUP_TYPE=${1:-full}
BACKUP_DIR="./backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_NAME="ai_chat_bot_backup_${TIMESTAMP}"

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ‚Ð¸Ð¿Ð° Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸
if [[ "$BACKUP_TYPE" != "full" && "$BACKUP_TYPE" != "database" && "$BACKUP_TYPE" != "files" ]]; then
    error "Invalid backup type. Use 'full', 'database', or 'files'"
fi

log "Starting $BACKUP_TYPE backup..."

# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð»Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ñ‹Ñ… ÐºÐ¾Ð¿Ð¸Ð¹
mkdir -p "$BACKUP_DIR"

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
if [[ -f ".env" ]]; then
    source .env
else
    warn ".env file not found, using default values"
fi

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
backup_database() {
    log "Creating database backup..."
    
    local db_backup_file="$BACKUP_DIR/${BACKUP_NAME}_database.sql"
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ°, Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð»Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    if docker-compose ps postgres | grep -q "Up"; then
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð°Ð¼Ð¿Ð° Ñ‡ÐµÑ€ÐµÐ· Docker
        docker-compose exec -T postgres pg_dump -U postgres -d ai_chat_bot > "$db_backup_file"
        log "Database backup created: $db_backup_file"
    elif command -v pg_dump &> /dev/null && [[ -n "$DATABASE_URL" ]]; then
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð°Ð¼Ð¿Ð° Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ (ÐµÑÐ»Ð¸ PostgreSQL ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾)
        pg_dump "$DATABASE_URL" > "$db_backup_file"
        log "Database backup created: $db_backup_file"
    else
        error "Cannot create database backup. PostgreSQL not available."
    fi
    
    # Ð¡Ð¶Ð°Ñ‚Ð¸Ðµ Ð´Ð°Ð¼Ð¿Ð°
    gzip "$db_backup_file"
    log "Database backup compressed: ${db_backup_file}.gz"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð²
backup_files() {
    log "Creating files backup..."
    
    local files_backup_file="$BACKUP_DIR/${BACKUP_NAME}_files.tar.gz"
    
    # Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð¸ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    local backup_items=(
        "uploads"
        "logs"
        ".env"
        "docker-compose.prod.yml"
        "docker/nginx.conf"
    )
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ñ€Ñ…Ð¸Ð²Ð° Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹
    local existing_items=()
    for item in "${backup_items[@]}"; do
        if [[ -e "$item" ]]; then
            existing_items+=("$item")
        fi
    done
    
    if [[ ${#existing_items[@]} -gt 0 ]]; then
        tar -czf "$files_backup_file" "${existing_items[@]}"
        log "Files backup created: $files_backup_file"
    else
        warn "No files found to backup"
    fi
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Redis
backup_redis() {
    log "Creating Redis backup..."
    
    local redis_backup_file="$BACKUP_DIR/${BACKUP_NAME}_redis.rdb"
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ°, Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð»Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€ Ñ Redis
    if docker-compose ps redis | grep -q "Up"; then
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ½Ð°Ð¿ÑˆÐ¾Ñ‚Ð° Redis
        docker-compose exec -T redis redis-cli BGSAVE
        
        # ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
        while [[ $(docker-compose exec -T redis redis-cli LASTSAVE) == $(docker-compose exec -T redis redis-cli LASTSAVE) ]]; do
            sleep 1
        done
        
        # ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð°Ð¼Ð¿Ð°
        docker-compose exec -T redis cat /data/dump.rdb > "$redis_backup_file"
        
        # Ð¡Ð¶Ð°Ñ‚Ð¸Ðµ Ð´Ð°Ð¼Ð¿Ð°
        gzip "$redis_backup_file"
        log "Redis backup created: ${redis_backup_file}.gz"
    else
        warn "Redis container is not running, skipping Redis backup"
    fi
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸
create_metadata() {
    local metadata_file="$BACKUP_DIR/${BACKUP_NAME}_metadata.json"
    
    cat > "$metadata_file" << EOF
{
    "backup_name": "$BACKUP_NAME",
    "backup_type": "$BACKUP_TYPE",
    "timestamp": "$TIMESTAMP",
    "date": "$(date -Iseconds)",
    "hostname": "$(hostname)",
    "user": "$(whoami)",
    "git_commit": "$(git rev-parse HEAD 2>/dev/null || echo 'unknown')",
    "git_branch": "$(git branch --show-current 2>/dev/null || echo 'unknown')",
    "docker_images": $(docker images --format "table {{.Repository}}:{{.Tag}}\t{{.ID}}\t{{.Size}}" | grep ai-chat-bot || echo '[]'),
    "environment_variables": {
        "NODE_ENV": "${NODE_ENV:-unknown}",
        "BOT_TOKEN": "${BOT_TOKEN:0:10}...",
        "OPENROUTER_MODEL": "${OPENROUTER_MODEL:-unknown}"
    }
}
EOF
    
    log "Metadata created: $metadata_file"
}

# Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¸Ð¿Ð°
case "$BACKUP_TYPE" in
    "database")
        backup_database
        ;;
    "files")
        backup_files
        ;;
    "full")
        backup_database
        backup_files
        backup_redis
        ;;
esac

# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…
create_metadata

# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¾Ð±Ñ‰ÐµÐ³Ð¾ Ð°Ñ€Ñ…Ð¸Ð²Ð° Ð´Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸
if [[ "$BACKUP_TYPE" == "full" ]]; then
    log "Creating full backup archive..."
    
    local full_backup_file="$BACKUP_DIR/${BACKUP_NAME}_full.tar.gz"
    
    # ÐŸÐ¾Ð¸ÑÐº Ð²ÑÐµÑ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸
    local backup_files=($(find "$BACKUP_DIR" -name "${BACKUP_NAME}_*" -type f))
    
    if [[ ${#backup_files[@]} -gt 0 ]]; then
        tar -czf "$full_backup_file" -C "$BACKUP_DIR" $(basename -a "${backup_files[@]}")
        
        # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¿Ð¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¾Ð±Ñ‰ÐµÐ³Ð¾ Ð°Ñ€Ñ…Ð¸Ð²Ð°
        rm -f "${backup_files[@]}"
        
        log "Full backup archive created: $full_backup_file"
    fi
fi

# ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ñ‹Ñ… ÐºÐ¾Ð¿Ð¸Ð¹ (Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 7)
log "Cleaning up old backups..."
find "$BACKUP_DIR" -name "ai_chat_bot_backup_*" -type f -mtime +7 -delete
log "Old backups cleaned up"

# Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸
backup_size=$(du -sh "$BACKUP_DIR" | cut -f1)
log "Total backup size: $backup_size"

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ†ÐµÐ»Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð²
log "Verifying backup integrity..."
for archive in "$BACKUP_DIR"/${BACKUP_NAME}_*.tar.gz; do
    if [[ -f "$archive" ]]; then
        if tar -tzf "$archive" >/dev/null 2>&1; then
            log "âœ… Archive integrity verified: $(basename "$archive")"
        else
            error "âŒ Archive integrity check failed: $(basename "$archive")"
        fi
    fi
done

for gzip_file in "$BACKUP_DIR"/${BACKUP_NAME}_*.gz; do
    if [[ -f "$gzip_file" && ! "$gzip_file" =~ \.tar\.gz$ ]]; then
        if gzip -t "$gzip_file" 2>/dev/null; then
            log "âœ… Gzip file integrity verified: $(basename "$gzip_file")"
        else
            error "âŒ Gzip file integrity check failed: $(basename "$gzip_file")"
        fi
    fi
done

# ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸ Ð² Ð¾Ð±Ð»Ð°ÐºÐ¾ (ÐµÑÐ»Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¾)
if [[ -n "$BACKUP_S3_BUCKET" && -n "$AWS_ACCESS_KEY_ID" ]]; then
    log "Uploading backup to S3..."
    
    if command -v aws &> /dev/null; then
        for backup_file in "$BACKUP_DIR"/${BACKUP_NAME}_*; do
            if [[ -f "$backup_file" ]]; then
                aws s3 cp "$backup_file" "s3://$BACKUP_S3_BUCKET/ai-chat-bot/" || warn "Failed to upload $(basename "$backup_file") to S3"
            fi
        done
        log "Backup uploaded to S3"
    else
        warn "AWS CLI not found, skipping S3 upload"
    fi
fi

# ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ Ð¾ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð¿Ð¸Ð¸
if [[ -n "$BACKUP_WEBHOOK_URL" ]]; then
    log "Sending backup notification..."
    
    curl -X POST "$BACKUP_WEBHOOK_URL" \
        -H "Content-Type: application/json" \
        -d "{\"text\":\"ðŸ’¾ AI Chat Bot backup completed: $BACKUP_TYPE backup created at $(date)\"}" \
        &> /dev/null || warn "Failed to send backup notification"
fi

# Ð’Ñ‹Ð²Ð¾Ð´ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
log "ðŸŽ‰ Backup completed successfully!"
echo ""
echo -e "${BLUE}Backup Summary:${NC}"
echo -e "${BLUE}===============${NC}"
echo -e "Type: ${GREEN}$BACKUP_TYPE${NC}"
echo -e "Timestamp: ${GREEN}$TIMESTAMP${NC}"
echo -e "Location: ${GREEN}$BACKUP_DIR${NC}"
echo -e "Size: ${GREEN}$backup_size${NC}"
echo ""
echo -e "${BLUE}Backup Files:${NC}"
echo -e "${BLUE}==============${NC}"
ls -lh "$BACKUP_DIR"/${BACKUP_NAME}_* 2>/dev/null || echo "No backup files found"
echo ""

log "Backup script completed!"
